{"cells":[{"cell_type":"markdown","metadata":{},"source":["Tải dataset tại link: https://www.kaggle.com/datasets/phanthhong/casia-dataset"]},{"cell_type":"code","execution_count":2,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-02-25T07:04:36.817311Z","iopub.status.busy":"2024-02-25T07:04:36.816817Z","iopub.status.idle":"2024-02-25T07:04:36.831498Z","shell.execute_reply":"2024-02-25T07:04:36.829988Z","shell.execute_reply.started":"2024-02-25T07:04:36.817273Z"},"trusted":true},"outputs":[],"source":["#import necessary libraries\n","import numpy as np\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","np.random.seed(2)\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import confusion_matrix\n","from keras.utils import to_categorical\n","from keras.models import Sequential\n","from keras.layers import Dense, Flatten, Conv2D, MaxPool2D, Dropout\n","from keras.optimizers import Adam\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.callbacks import EarlyStopping\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from PIL import Image, ImageChops, ImageEnhance\n","import os\n","import itertools"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"outputs":[],"source":["def convert_to_ela_image(path, quality):\n","    temp_filename = 'temp_file_name.jpg'\n","    ela_filename = 'temp_ela.png'\n","    \n","    image = Image.open(path).convert('RGB')\n","    image.save(temp_filename, 'JPEG', quality = quality)\n","    temp_image = Image.open(temp_filename)\n","    \n","    ela_image = ImageChops.difference(image, temp_image)\n","    \n","    extrema = ela_image.getextrema()\n","    max_diff = max([ex[1] for ex in extrema])\n","    if max_diff == 0:\n","        max_diff = 1\n","    scale = 255.0 / max_diff\n","    \n","    ela_image = ImageEnhance.Brightness(ela_image).enhance(scale)\n","    \n","    return ela_image"]},{"cell_type":"markdown","metadata":{},"source":["**Open a real image**"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["real_image_path = '/kaggle/input/real-and-fake-images/Au/Au_ani_00001.jpg'\n","Image.open(real_image_path)"]},{"cell_type":"markdown","metadata":{},"source":["**After converting to ELA image**"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["convert_to_ela_image(real_image_path, 90)"]},{"cell_type":"markdown","metadata":{},"source":["**Open a fake image**"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["fake_image_path = '/kaggle/input/real-and-fake-images/Tp/Tp_D_NRN_S_N_ani10171_ani00001_12458.jpg'\n","Image.open(fake_image_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["convert_to_ela_image(fake_image_path, 90)"]},{"cell_type":"markdown","metadata":{},"source":["**Dataset Preparation**"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["image_size = (128, 128)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def prepare_image(image_path):\n","    return np.array(convert_to_ela_image(image_path, 90).resize(image_size)).flatten() / 255.0"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["X = [] # ELA converted images\n","Y = [] # 0 for fake, 1 for real"]},{"cell_type":"markdown","metadata":{},"source":["**Au => Total Images 7491, Take 2100 random images from the list\n","Tp => Total Images 2064**"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import random\n","path = '/kaggle/input/real-and-fake-images/Au/'\n","for dirname, _, filenames in os.walk(path):\n","    for filename in filenames:\n","        if filename.endswith('jpg') or filename.endswith('png'):\n","            full_path = os.path.join(dirname, filename)\n","            X.append(prepare_image(full_path))\n","            Y.append(1)\n","            if len(Y) % 500 == 0:\n","                print(f'Processing {len(Y)} images')\n","\n","random.shuffle(X)\n","X = X[:2100]\n","Y = Y[:2100]\n","print(len(X), len(Y))"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["path = '/kaggle/input/real-and-fake-images/Tp/'\n","for dirname, _, filenames in os.walk(path):\n","    for filename in filenames:\n","        if filename.endswith('jpg') or filename.endswith('png'):\n","            full_path = os.path.join(dirname, filename)\n","            X.append(prepare_image(full_path))\n","            Y.append(0)\n","            if len(Y) % 500 == 0:\n","                print(f'Processing {len(Y)} images')\n","\n","print(len(X), len(Y))"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["X = np.array(X)\n","Y = to_categorical(Y, 2)\n","X = X.reshape(-1, 128, 128, 3)"]},{"cell_type":"markdown","metadata":{},"source":["**Train Test split with 80:20 ratio**"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size = 0.2, random_state=5)\n","X = X.reshape(-1,1,1,1)\n","print(len(X_train), len(Y_train))\n","print(len(X_val), len(Y_val))"]},{"cell_type":"markdown","metadata":{},"source":["**CNN Model**"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def build_model():\n","    model = Sequential()\n","    model.add(Conv2D(filters = 32, kernel_size = (5, 5), padding = 'valid', activation = 'relu', input_shape = (128, 128, 3)))\n","    model.add(Conv2D(filters = 32, kernel_size = (5, 5), padding = 'valid', activation = 'relu', input_shape = (128, 128, 3)))\n","    model.add(MaxPool2D(pool_size = (2, 2)))\n","    model.add(Dropout(0.25))\n","    model.add(Flatten())\n","    model.add(Dense(256, activation = 'relu'))\n","    model.add(Dropout(0.5))\n","    model.add(Dense(2, activation = 'softmax'))\n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["model = build_model()\n","model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["epochs = 30\n","batch_size = 32\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["init_lr = 1e-4\n","optimizer = Adam(lr = init_lr, decay = init_lr/epochs)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["model.compile(optimizer = optimizer, loss = 'binary_crossentropy', metrics = ['accuracy'])"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["early_stopping = EarlyStopping(monitor = 'val_acc',\n","                              min_delta = 0,\n","                              patience = 2,\n","                              verbose = 0,\n","                              mode = 'auto')"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["hist = model.fit(X_train,\n","                 Y_train,\n","                 batch_size = batch_size,\n","                 epochs = epochs,\n","                validation_data = (X_val, Y_val),\n","                callbacks = [early_stopping])"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["model.save('model_casia_run1.h5')"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Plot the loss and accuracy curves for training and validation \n","fig, ax = plt.subplots(2,1)\n","ax[0].plot(hist.history['loss'], color='b', label=\"Training loss\")\n","ax[0].plot(hist.history['val_loss'], color='r', label=\"validation loss\",axes =ax[0])\n","legend = ax[0].legend(loc='best', shadow=True)\n","\n","ax[1].plot(hist.history['accuracy'], color='b', label=\"Training accuracy\")\n","ax[1].plot(hist.history['val_accuracy'], color='r',label=\"Validation accuracy\")\n","legend = ax[1].legend(loc='best', shadow=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def plot_confusion_matrix(cm, classes,\n","                          normalize=False,\n","                          title='Confusion matrix',\n","                          cmap=plt.cm.Blues):\n","    \"\"\"\n","    This function prints and plots the confusion matrix.\n","    Normalization can be applied by setting `normalize=True`.\n","    \"\"\"\n","    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n","    plt.title(title)\n","    plt.colorbar()\n","    tick_marks = np.arange(len(classes))\n","    plt.xticks(tick_marks, classes, rotation=45)\n","    plt.yticks(tick_marks, classes)\n","\n","    if normalize:\n","        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n","\n","    thresh = cm.max() / 2.\n","    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n","        plt.text(j, i, cm[i, j],\n","                 horizontalalignment=\"center\",\n","                 color=\"white\" if cm[i, j] > thresh else \"black\")\n","\n","    plt.tight_layout()\n","    plt.ylabel('True label')\n","    plt.xlabel('Predicted label')\n","    \n","    \n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Predict the values from the validation dataset\n","Y_pred = model.predict(X_val)\n","# Convert predictions classes to one hot vectors \n","Y_pred_classes = np.argmax(Y_pred,axis = 1) \n","# Convert validation observations to one hot vectors\n","Y_true = np.argmax(Y_val,axis = 1) \n","# compute the confusion matrix\n","confusion_mtx = confusion_matrix(Y_true, Y_pred_classes) \n","# plot the confusion matrix\n","plot_confusion_matrix(confusion_mtx, classes = range(2))"]},{"cell_type":"markdown","metadata":{},"source":["**Prediction**"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["class_names = ['fake', 'real']"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["fake_image = os.listdir('/kaggle/input/real-and-fake-images/Tp/')\n","correct = 0\n","total = 0\n","for file_name in fake_image:\n","    if file_name.endswith('jpg') or filename.endswith('png'):\n","        fake_image_path = os.path.join('/kaggle/input/real-and-fake-images/Tp/', file_name)\n","        image = prepare_image(fake_image_path)\n","        image = image.reshape(-1, 128, 128, 3)\n","        y_pred = model.predict(image)\n","        y_pred_class = np.argmax(y_pred, axis = 1)[0]\n","        total += 1\n","        if y_pred_class == 0:\n","            correct += 1\n","#             print(f'Class: {class_names[y_pred_class]} Confidence: {np.amax(y_pred) * 100:0.2f}')"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["print(f'Total: {total}, Correct: {correct}, Acc: {correct / total * 100.0}')"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["real_image = os.listdir('/kaggle/input/real-and-fake-images/Au/')\n","correct_r = 0\n","total_r = 0\n","for file_name in real_image:\n","    if file_name.endswith('jpg') or filename.endswith('png'):\n","        real_image_path = os.path.join('/kaggle/input/real-and-fake-images/Au/', file_name)\n","        image = prepare_image(real_image_path)\n","        image = image.reshape(-1, 128, 128, 3)\n","        y_pred = model.predict(image)\n","        y_pred_class = np.argmax(y_pred, axis = 1)[0]\n","        total_r += 1\n","        if y_pred_class == 1:\n","            correct_r += 1\n","#             print(f'Class: {class_names[y_pred_class]} Confidence: {np.amax(y_pred) * 100:0.2f}')"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["correct += correct_r\n","total += total_r\n","print(f'Total: {total_r}, Correct: {correct_r}, Acc: {correct_r / total_r * 100.0}')\n","print(f'Total: {total}, Correct: {correct}, Acc: {correct / total * 100.0}')"]},{"cell_type":"markdown","metadata":{},"source":["**Test model**"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["image_path = 'test_path'\n","image = prepare_image(image_path)\n","image = image.reshape(-1, 128, 128, 3)\n","y_pred = model.predict(image)\n","y_pred_class = np.argmax(y_pred, axis = 1)[0]\n","print(f'Class: {class_names[y_pred_class]} Confidence: {np.amax(y_pred) * 100:0.2f}')"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":4475550,"sourceId":7672818,"sourceType":"datasetVersion"},{"datasetId":4475599,"sourceId":7672888,"sourceType":"datasetVersion"}],"dockerImageVersionId":30004,"isGpuEnabled":true,"isInternetEnabled":false,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.11"}},"nbformat":4,"nbformat_minor":4}
